# -*- coding: utf-8 -*-
"""Ecommerce_Product_Delivery_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dzA1p6Q4uJq2CBBS-qpBhnN5dxj_MHG8

# Ecommerce Product Delivery Prediction

## Objective

The objective of this project is to develop a machine learning model to predict whether an e-commerce product will be delivered on time based on product properties, logistics details, and customer-related factors. By identifying the key drivers of delivery performance, the project aims to help e-commerce companies optimize supply chain efficiency, improve customer satisfaction, and reduce late deliveries.

##  Import the Required Libraries
"""

#Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_absolute_error, r2_score, mean_squared_error

"""## Data Loading"""

df = pd.read_csv("/content/E_Commerce.csv")
df.head()

"""## Data Cleaning"""

df.shape

df.dtypes

df.drop(['ID'], axis=1, inplace=True)

df.isnull().sum()

df.duplicated().sum()

df.describe()

df.head()

"""## Exploratory Data Analysis**"""

plt.pie(df['Gender'].value_counts(),labels = ['F','M'], autopct='%1.1f%%', startangle=90)
plt.title('Gender Distribution')

"""##Product Properties and Product Delivery

"""

fig, ax = plt.subplots(1,3,figsize=(15,5))
sns.histplot(df['Weight_in_gms'], ax=ax[0], kde=True).set_title('Weight Distribution')
sns.countplot(x = 'Product_importance', data = df, ax=ax[1]).set_title('Product Importance')
sns.histplot(df['Cost_of_the_Product'], ax=ax[2], kde=True).set_title('Cost of the Product')

"""##Logistics and Product Delivery"""

fig, ax = plt.subplots(1,3,figsize=(15,5))
sns.countplot(x = 'Warehouse_block', data = df, ax=ax[0]).set_title('Warehouse Block')
sns.countplot(x = 'Mode_of_Shipment', data = df, ax=ax[1]).set_title('Mode of Shipment')
sns.countplot(x = 'Reached.on.Time_Y.N', data = df, ax=ax[2]).set_title('Reached on Time')

"""##Customer Experience and Product Delivery"""

fig, ax = plt.subplots(2,2,figsize=(15,10))
sns.countplot(x = 'Customer_care_calls', data = df, ax=ax[0,0]).set_title('Customer Care Calls')
sns.countplot(x = 'Customer_rating', data = df, ax=ax[0,1]).set_title('Customer Rating')
sns.countplot(x = 'Prior_purchases', data = df, ax=ax[1,0]).set_title('Prior Purchases')
sns.histplot(x = 'Discount_offered', data = df, ax=ax[1,1], kde = True).set_title('Discount Offered')

"""##Customer Gender and Product Delivery"""

sns.countplot(x = 'Gender', data = df, hue = 'Reached.on.Time_Y.N').set_title('Gender vs Reached on Time')

"""##Product Properties and Product Delivery

"""

fig, ax = plt.subplots(1,3,figsize=(15,5))
sns.violinplot(y = df['Weight_in_gms'], ax=ax[0], x = df['Reached.on.Time_Y.N']).set_title('Weight Distribution')
sns.countplot(x = 'Product_importance', data = df, ax=ax[1], hue = 'Reached.on.Time_Y.N').set_title('Product Importance')
sns.violinplot(y = df['Cost_of_the_Product'], ax=ax[2], x = df['Reached.on.Time_Y.N']).set_title

"""##Logistics and Product Delivery

"""

fig, ax = plt.subplots(1,2,figsize=(15,5))
sns.countplot(x = 'Warehouse_block', data = df, ax=ax[0], hue = 'Reached.on.Time_Y.N').set_title('Warehouse Block')
sns.countplot(x = 'Mode_of_Shipment', data = df, ax=ax[1], hue = 'Reached.on.Time_Y.N').set_title('Mode of Shipment')

"""##Customer Experience and Product Delivery"""

fig, ax = plt.subplots(2,2,figsize=(15,10))
sns.countplot(x = 'Customer_care_calls', data = df, ax=ax[0,0],hue = 'Reached.on.Time_Y.N').set_title('Customer Care Calls')
sns.countplot(x = 'Customer_rating', data = df, ax=ax[0,1],hue = 'Reached.on.Time_Y.N').set_title('Customer Rating')
sns.countplot(x = 'Prior_purchases', data = df, ax=ax[1,0],hue = 'Reached.on.Time_Y.N').set_title('Prior Purchases')
sns.violinplot(x = 'Reached.on.Time_Y.N', y = 'Discount_offered' ,data = df, ax=ax[1,1]).set_title('Discount Offered')

"""Label Encoding the Categorical Variables"""

#Label encoding object
le = LabelEncoder()

cols = ['Warehouse_block','Mode_of_Shipment','Product_importance', 'Gender']

#label encoding
for i in cols:
    le.fit(df[i])
    df[i] = le.transform(df[i])
    print(i, df[i].unique())

"""##Correlation Matrix Heatmap




"""

plt.figure(figsize=(10,10))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')

sns.violinplot(x = 'Customer_care_calls', y = 'Cost_of_the_Product', data = df)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(df.drop('Reached.on.Time_Y.N', axis=1), df['Reached.on.Time_Y.N'], test_size=0.2, random_state=0)

"""##Random Forest Classifier





"""

#Random Forest Classifier Object
rfc = RandomForestClassifier()

#Parameter grid
param_grid = {
    'max_depth': [4,8,12,16],
    'min_samples_leaf': [2,4,6,8],
    'min_samples_split': [2,4,6,8],
    'criterion': ['gini', 'entropy'],
    'random_state': [0,42]
}

#GridSearchCV object
grid = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')

#Fitting the model
grid.fit(X_train, y_train)

#Best parameters
print('Best parameters: ', grid.best_params_)

"""##Random Forest Classifier"""

#Random Forest Classifier Object
rfc = RandomForestClassifier(criterion='gini', max_depth=8, min_samples_leaf=8, min_samples_split=2, random_state=42)

#Fitting the model
rfc.fit(X_train, y_train)

#Training accuracy
print('Training accuracy: ', rfc.score(X_train, y_train))

#predicting the test set results
rfc_pred = rfc.predict(X_test)

"""#Decision Tree Classifier Object"""

dtc = DecisionTreeClassifier()

param_grid = {
    'max_depth': [2,4,6,8],
    'min_samples_leaf': [2,4,6,8],
    'min_samples_split': [2,4,6,8],
    'criterion': ['gini', 'entropy'],
    'random_state': [0,42]}

grid = GridSearchCV(estimator=dtc, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')

#predicting the test set results
grid.fit(X_train, y_train)

print('Best parameters: ', grid.best_params_)

"""##Decision Tree Classifier"""

#Decision Tree Classifier Object
dtc = DecisionTreeClassifier(criterion='gini', max_depth=6, min_samples_leaf=6, min_samples_split=2, random_state=0, class_weight='balanced')

#Fitting the model
dtc.fit(X_train, y_train)

#Training accuracy
print('Training accuracy: ', dtc.score(X_train, y_train))

#predicting the test set results
dtc_pred = dtc.predict(X_test)

"""##Logistic Regression"""

#Logistic Regression Object
lr = LogisticRegression()

lr.fit(X_train, y_train)

#Training accuracy
lr.score(X_train, y_train)

#predicting the test set results
lr_pred = lr.predict(X_test)

"""##K Nearest Neighbors"""

#KNN Classifier Object
knn = KNeighborsClassifier()

#fitting the model
knn.fit(X_train, y_train)

#training accuracy
knn.score(X_train, y_train)

#predicting the test set results
knn_pred = knn.predict(X_test)

"""##Model Evaluation"""

fig, ax = plt.subplots(2,2,figsize=(15,10))
sns.heatmap(confusion_matrix(y_test, rfc_pred), annot=True, cmap='coolwarm', ax=ax[0,0]).set_title('Random Forest Classifier')
sns.heatmap(confusion_matrix(y_test, dtc_pred), annot=True, cmap='coolwarm', ax=ax[0,1]).set_title('Decision Tree Classifier')
sns.heatmap(confusion_matrix(y_test, lr_pred), annot=True, cmap='coolwarm', ax=ax[1,0]).set_title('Logistic Regression')
sns.heatmap(confusion_matrix(y_test, knn_pred), annot=True, cmap='coolwarm', ax=ax[1,1]).set_title('KNN Classifier')

#classification report
print('Random Forest Classifier: \n', classification_report(y_test, rfc_pred))
print('Decision Tree Classifier: \n', classification_report(y_test, dtc_pred))
print('Logistic Regression: \n', classification_report(y_test, lr_pred))
print('KNN Classifier: \n', classification_report(y_test, knn_pred))

"""##Model Comparison"""

models = ['Random Forest Classifier', 'Decision Tree Classifier', 'Logistic Regression', 'KNN Classifier']
accuracy = [accuracy_score(y_test, rfc_pred), accuracy_score(y_test, dtc_pred), accuracy_score(y_test, lr_pred), accuracy_score(y_test, knn_pred)]
sns.barplot(x=models, y=accuracy, palette='magma').set_title('Model Comparison')
plt.xticks(rotation=90)
plt.ylabel('Accuracy')

"""## Conclusion
1. **Key Findings:**
   - **Product weight** between **2500–3500 grams** and cost under **$250** were strongly linked to timely deliveries.
   - **Warehouse F**, likely near a seaport, recorded the highest shipping volume.
   - More **customer care calls** correlated with delays, while **repeat customers** had higher on-time delivery rates.
   - Products with **small discounts (0–10%)** experienced more late deliveries compared to those with **larger discounts (>10%)**.

2. **Model Performance:**
   - **Decision Tree Classifier:** Highest accuracy (**69%**)
   - **Random Forest:** 68% accuracy, with better generalization stability
   - **K-Nearest Neighbors:** 65% accuracy
   - **Logistic Regression:** 63% accuracy

3. **Business Implications:**
   - Both **product attributes** and **logistics efficiency** significantly influence delivery performance.
   - Insights from this project can guide operational strategies such as inventory management, route planning, and customer engagement to improve delivery reliability.

"""